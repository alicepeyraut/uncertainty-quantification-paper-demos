{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures: uncertainty quantification for measurement errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dolfin  # https://fenicsproject.org\n",
    "import numpy\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import helpers\n",
    "import compute_disp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dolfin_mech as dmech\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger('FFC').setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Material and loading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### parameters should be given as dictionary; additionally the parameter alpha_fibrose_i should increase as i increases\n",
    "\n",
    "# ## Figure 4\n",
    "# parameters_to_identify = {\"alpha\":0.09}\n",
    "\n",
    "# ## Figure 5\n",
    "# parameters_to_identify = {\"pi\":-2}\n",
    "\n",
    "## Figure 6 - top row\n",
    "parameters_to_identify = {\"alpha_healthy\":0.09, \"pi\":-2}\n",
    "\n",
    "## Figure  7 - top row\n",
    "# parameters_to_identify = {\"alpha_healthy\":0.09, \"alpha_fibrose\":0.9}\n",
    "\n",
    "# ## Figure  8 - top row\n",
    "# parameters_to_identify = {\"alpha_fibrose\":0.9, \"pi\":-2}\n",
    "\n",
    "# ## Figure  9 - top row\n",
    "# parameters_to_identify = {\"alpha_fibrose_1\":0.9, \"alpha_fibrose_2\":0.67, \"pi\":-2}\n",
    "\n",
    "# ## Figure 10 / 12 - top row \n",
    "# parameters_to_identify = {\"alpha_fibrose_1\":1.1, \"alpha_fibrose_2\":0.9, \"alpha_fibrose_3\":0.67, \"pi\":-2}\n",
    "\n",
    "# ## Figure 11 - top row \n",
    "# parameters_to_identify = {\"alpha_healthy\": 0.09, \"alpha_fibrose\": 0.67, \"pi\":-2}\n",
    "\n",
    "\n",
    "nb_parameters = len(parameters_to_identify)\n",
    "\n",
    "reference_value = []\n",
    "param_names = []\n",
    "\n",
    "for param_name, param_value in parameters_to_identify.items():\n",
    "    reference_value.append(param_value)\n",
    "    param_names.append(param_name)\n",
    "\n",
    "\n",
    "### default parameter values \n",
    "alpha, alpha_healthy, alpha_fibrose, alpha_fibrose_1, alpha_fibrose_2, alpha_fibrose_3 = 0.09, 0.09, 0.67, 0.67, 0.9, 1.1 ### reference stiffnesses in kPa\n",
    "gamma = 0.5 ### [-]\n",
    "c1, c2 = 0.2, 0.4 ### in kPa\n",
    "pe, pi = -0.5, -2 ### end-exhalation and end-inhalation pleural pressures, in kPa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [\"Supine\", \"Prone\", \"Supine+Prone\"] ### supine, prone, prone + supine\n",
    "\n",
    "noise_lst = [0., 1/20, 1/10, 1/5, 1/2.5]\n",
    "SNR_lst = [ (2/noise_lst[i+1] if noise_lst[i] == 0 else 1/noise_lst[i]) for i in range(len(noise_lst))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generic mesh is stored in Data folder\n",
    "cube_params = {\"path_and_mesh_name\": \"./Data/test.xdmf\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### unloading problem\n",
    "\n",
    "### generic unloading problem, no gravity is applied\n",
    "load_params_unloading_generic = {\"type\":\"p_boundary_condition0\", \"f\":0, \"P0\" : float(pe)} \n",
    "\n",
    "### loading problem\n",
    "\n",
    "### generic end-exhalation configuration in prone and in supine positions\n",
    "load_params_loading_prone = {\"type\":\"p_boundary_condition\", \"f\": -9.81e3, \"P0\" : float(pe)}\n",
    "load_params_loading_supine = {\"type\":\"p_boundary_condition\", \"f\": 9.81e3, \"P0\" : float(pe)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "directory_prone = current_directory + \"/prone\" ### storing the results created for prone position\n",
    "directory_supine = current_directory + \"/supine\" ### storing the results created for supine position\n",
    "\n",
    "### creating associated directories, if do not already exist\n",
    "\n",
    "try:\n",
    "    os.mkdir(directory_prone)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(directory_supine)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize_lsts():\n",
    "\n",
    "    storing_processes = {} ### storing processes launched in parallel\n",
    "\n",
    "    results = {} ### storing the results of the estimation, for each noise level\n",
    "    storing_values_for_convergence_check = {} ### storing the results for convergence checks\n",
    "\n",
    "    ### initializing lists in results dict\n",
    "    results['noise'] = []\n",
    "\n",
    "    for param_name in param_names:\n",
    "        lst_name = \"ini_\"+str(param_name)\n",
    "        results[lst_name] = []\n",
    "        results[param_name] = []\n",
    "\n",
    "    for noise in noise_lst:\n",
    "        storing_values_for_convergence_check[str(noise)] = []\n",
    "        for i in range(nb_parameters):\n",
    "            storing_values_for_convergence_check[str(noise)].append([])\n",
    "\n",
    "    return(results, storing_values_for_convergence_check, storing_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write reference end-exhalation configurations -prone and supine- from Zygot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating mesh for end-exhalation prone and supine\n",
    "mesh_prone = dolfin.Mesh()\n",
    "mesh_supine = dolfin.Mesh()\n",
    "mesh_name = str(cube_params[\"path_and_mesh_name\"])\n",
    "dolfin.XDMFFile(mesh_name).read(mesh_prone)\n",
    "dolfin.XDMFFile(mesh_name).read(mesh_supine)\n",
    "\n",
    "### generic configurations, computed with one zone for the sake of simplicity\n",
    "parameters = {\"alpha\": alpha, \"gamma\":gamma, \"c1\":c1, \"c2\":c2, \"kappa\":1e2, \"eta\":1e-5}\n",
    "mat_params={\"scaling\": \"linear\", \"parameters\": parameters}\n",
    "\n",
    "### computing unloaded configuration from generic Zygot\n",
    "U_unloading, phis_unloading, dV_unloading = dmech.run_RivlinCube_PoroHyperelasticity(\n",
    "    dim = 3,\n",
    "    inverse = 1,\n",
    "    cube_params = cube_params,\n",
    "    porosity_params = {\"type\": \"mesh_function_random_xml\"},\n",
    "    get_results = 1,\n",
    "    mat_params = mat_params,\n",
    "    step_params = {\"dt_min\":1e-4},\n",
    "    load_params = load_params_unloading_generic,\n",
    "    res_basename = \"generic_unloaded\",\n",
    "    inertia_params = {\"applied\":True},\n",
    "    plot_curves = 0,\n",
    "    verbose =1 )\n",
    "\n",
    "#### redefining porosity field in the unloaded configuration so it is physiological\n",
    "phisref_imposed = list(numpy.random.uniform(low = 0.4, high = 0.6, size = len(phis_unloading)))\n",
    "\n",
    "#### computing end-exhalation configuration prone position\n",
    "Uprone, phisprone, dVprone = dmech.run_RivlinCube_PoroHyperelasticity(\n",
    "    dim = 3,\n",
    "    inverse = 0,\n",
    "    porosity_params = {\"type\":\"function_xml_from_array\", \"val\":phisref_imposed},\n",
    "    cube_params = cube_params,\n",
    "    mat_params = mat_params,\n",
    "    step_params = {\"dt_ini\": 0.125, \"dt_min\": 1e-4},\n",
    "    load_params = load_params_loading_prone,\n",
    "    res_basename = directory_prone+\"/prone\",\n",
    "    move_params = {\"move\": True, \"U\": U_unloading}, ### applying the displacement field from generic end-exhalation configuration to unloaded configuration\n",
    "    inertia_params={\"applied\":True},\n",
    "    get_results = 1,\n",
    "    plot_curves = 0,\n",
    "    verbose = 1)\n",
    "\n",
    "helpers.write_porosity(porosity_field = phisprone, n_cells = len(mesh_prone.cells()), filepath = directory_prone + \"prone-poro.xml\")\n",
    "\n",
    "### getting displacement field from generic end-exhalation to prone end-exhalation configuration\n",
    "Uexhal_prone = U_unloading.copy(deepcopy=True)\n",
    "Uexhal_prone.vector()[:] +=  Uprone.vector()[:]\n",
    "dolfin.ALE.move(mesh_prone, Uexhal_prone)\n",
    "\n",
    "### writing mesh prone\n",
    "xdmf_file_mesh = dolfin.XDMFFile(\"prone/Zygotprone.xdmf\")\n",
    "xdmf_file_mesh.write(mesh_prone)\n",
    "xdmf_file_mesh.close()\n",
    "\n",
    "\n",
    "#### computing end-exhalation configuration supine position\n",
    "Usupine, phissupine, dVsupine = dmech.run_RivlinCube_PoroHyperelasticity(\n",
    "    dim = 3,\n",
    "    inverse = 0,\n",
    "    porosity_params = {\"type\":\"function_xml_from_array\", \"val\":phisref_imposed},\n",
    "    cube_params = cube_params,\n",
    "    mat_params = mat_params,\n",
    "    step_params = {\"dt_ini\": 0.125, \"dt_min\": 1e-4},\n",
    "    load_params = load_params_loading_supine,\n",
    "    res_basename = directory_supine+\"/supine\",\n",
    "    move_params = {\"move\": True, \"U\": U_unloading},  ### applying the displacement field from generic end-exhalation configuration to unloaded configuration\n",
    "    inertia_params={\"applied\": True},\n",
    "    get_results = 1,\n",
    "    plot_curves=0,\n",
    "    verbose=1)\n",
    "\n",
    "helpers.write_porosity(porosity_field = phissupine, n_cells = len(mesh_supine.cells()), filepath = directory_supine + \"/supine-poro.xml\")\n",
    "\n",
    "### getting displacement field from generic end-exhalation to prone end-exhalation configuration\n",
    "Uexhal_supine = U_unloading.copy(deepcopy=True)\n",
    "Uexhal_supine.vector()[:] +=  Usupine.vector()[:]\n",
    "dolfin.ALE.move(mesh_supine, Uexhal_supine)\n",
    "\n",
    "### writing mesh supine\n",
    "xdmf_file_mesh = dolfin.XDMFFile(directory_supine+\"/Zygotsupine.xdmf\")\n",
    "xdmf_file_mesh.write(mesh_supine)\n",
    "xdmf_file_mesh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_and_writing(positions = ['Supine'], parameters_to_identify={}, results = {}):\n",
    "    \n",
    "    for parameter_name, value in parameters_to_identify.items():\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.cla()\n",
    "        ### plotting parameters\n",
    "        plt.rc(\"xtick\", labelsize=18)\n",
    "        plt.rc(\"ytick\", labelsize=18)\n",
    "        plt.rc(\"legend\", fontsize=16)\n",
    "        plt.ylim([-100, 100])\n",
    "        plt.xlabel(\"Signal to Noise Ratio (SNR)\", fontsize=14)\n",
    "        plt.ylabel(\"Estimation error (%)\", fontsize=14)\n",
    "        color_lst=['royalblue', 'firebrick', 'forestgreen'] ### different color for each position\n",
    "        color_lst_lines=['royalblue', 'firebrick', 'darkgreen']\n",
    "        alpha_lst=[0.6, 0.45, 0.6] ### transparencies to be able \n",
    "        label_lst = positions \n",
    "        for position in positions:\n",
    "            ### reorganize data \n",
    "            results_position = results[position]\n",
    "            frame = pd.DataFrame(results_position)\n",
    "            sorted_frame = frame.sort_values(by=\"noise\")\n",
    "            parametrization_name = ''\n",
    "        \n",
    "            stats_results = sorted_frame.groupby(\"noise\")[str(parameter_name)].agg(['mean', 'std'])\n",
    "            stats_results['mean_'+str(parameter_name)] = stats_results['mean']\n",
    "            stats_results['mean_plus_std'+str(parameter_name)] = stats_results['mean'] + stats_results['std']\n",
    "            stats_results['mean_minus_std'+str(parameter_name)] = stats_results['mean'] - stats_results['std']\n",
    "            parametrization_name += parameter_name\n",
    "\n",
    "            plt.plot(SNR_lst, stats_results['mean_'+str(parameter_name)], color=color_lst_lines[0], label=label_lst[0])\n",
    "            ax.fill_between(SNR_lst, stats_results['mean_minus_std'+str(parameter_name)], stats_results['mean_plus_std'+str(parameter_name)], alpha=alpha_lst[0], color=color_lst[0])\n",
    "            color_lst=color_lst[1:]\n",
    "            label_lst=label_lst[1:]\n",
    "            alpha_lst=alpha_lst[1:]\n",
    "            color_lst_lines=color_lst_lines[1:]\n",
    "        plt.xlim([2.5, 44])\n",
    "        plt.gca().set_xscale('log')\n",
    "        ax.errorbar(SNR_lst, len(SNR_lst)*[0], yerr=30, linewidth=1, markersize=10, color='black', fmt='x', capsize=5, label=\"Initial distribution\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        plt.savefig(\"parametrization=\"+parametrization_name+\"_identification_parameter=\"+str(parameter_name)+\"_position=\"+str(position)+\"_impact_measurement_errors.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_positions = {}\n",
    "for position in positions:\n",
    "    print(\"position\", position)\n",
    "    distribution_converged = ['no'] * len(noise_lst) ### is the distribution converged for each noise level?\n",
    "\n",
    "    results, storing_values_for_convergence_check, storing_processes = reinitialize_lsts()\n",
    "\n",
    "    ########### computation of reference displacement field\n",
    "    if position=='Supine+Prone':\n",
    "        \n",
    "        ### computing displacement field in supine position\n",
    "        Umeas_supine, Vmeas_supine = compute_disp.compute_disp(gravity_type = 'Supine', parameters_to_identify = parameters_to_identify, noise='', dirpath = current_directory)\n",
    "        V0_supine = dolfin.assemble(dolfin.Constant(1)*Vmeas_supine)\n",
    "        Umeas_norm_supine = (dolfin.assemble(dolfin.inner(Umeas_supine, Umeas_supine)*Vmeas_supine)/2/V0_supine)**(1/2)\n",
    "\n",
    "        ### writing displacement field supine position\n",
    "        file_supine = dolfin.File(\"refSupine/displacement_exhal_to_inhal.xml\")\n",
    "        file_supine << Umeas_supine\n",
    "        file_supine.close()\n",
    "\n",
    "        ### computing displacement field in prone position\n",
    "        Umeas_prone, Vmeas_prone = compute_disp.compute_disp(gravity_plus = 'Prone', parameters_to_identify = parameters_to_identify, noise='', dirpath = current_directory)\n",
    "        V0_prone = dolfin.assemble(dolfin.Constant(1)*Vmeas_prone)\n",
    "        Umeas_norm_prone = (dolfin.assemble(dolfin.inner(Umeas_prone, Umeas_prone)*Vmeas_prone)/2/V0_prone)**(1/2)\n",
    "\n",
    "        ### writing displacement field prone position\n",
    "        file_prone = dolfin.File(\"refProne/displacement_exhal_to_inhal.xml\")\n",
    "        file_prone << Umeas_prone\n",
    "\n",
    "    else :\n",
    "        Umeas, Vmeas = compute_disp.compute_disp(position = position, parameters_to_identify = parameters_to_identify, noise = '', dirpath = current_directory)\n",
    "        V0 = dolfin.assemble(dolfin.Constant(1)*Vmeas)\n",
    "        Umeas_norm = (dolfin.assemble(dolfin.inner(Umeas, Umeas)*Vmeas)/2/V0)**(1/2)\n",
    "\n",
    "        ### writing displacement field in prone or supine (depending on the case investigated) position\n",
    "        file_prone = dolfin.File(\"ref\"+str(position)+\"/displacement_exhal_to_inhal.xml\")\n",
    "        file_prone << Umeas\n",
    "\n",
    "\n",
    "    number_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "    min_iterations = number_cpus // len(noise_lst) ### arbitrary, to change depending on the resource available for example\n",
    "\n",
    "    converged = False ### convergence of the error distributions\n",
    "    while not converged:\n",
    "        converged = all(convergence_status == \"converged\" for convergence_status in distribution_converged)\n",
    "        over = False\n",
    "        for i in range(len(noise_lst)):\n",
    "            if distribution_converged[i] == 'converged':\n",
    "                storing_processes.pop(str(noise_lst[i]), None)\n",
    "            elif distribution_converged[i] == 'no':\n",
    "                storing_processes[str(noise_lst[i])] = []\n",
    "\n",
    "        for noise, lst in storing_processes.items():\n",
    "            if lst == []:\n",
    "                for iteration in range(0, min_iterations):\n",
    "                    ini_calculation = []\n",
    "                    for param, param_value in parameters_to_identify.items():\n",
    "                        ini_calculation.append(float(numpy.random.normal(loc = param_value, scale = abs(0.3*param_value), size = 1)[0]))\n",
    "                    process = subprocess.Popen([\"python\",  \"-W\", \"%s\" %\"ignore\", \"./minimization.py\", \"--position\", \"%s\" %position, \"--noise_level\", \"%s\" %noise, \"--parameters_to_identify\", \"%s\" %parameters_to_identify, \"--iteration\", \"%s\" %iteration, \"--dirpath\", \"%s\" %current_directory, \"--initialization\", \"%s\" %ini_calculation], stdout=subprocess.PIPE )\n",
    "                    storing_processes[str(noise)].append(process)\n",
    "        while not over:\n",
    "            time.sleep(1)\n",
    "            for noise, lst in storing_processes.items():\n",
    "                noise = float(noise)\n",
    "                over = helpers.checking_if_processes_converged(storing_processes[str(noise)])\n",
    "                if over:\n",
    "                    for process in storing_processes[str(noise)]:\n",
    "                        try:\n",
    "                            out = process.communicate()[0]\n",
    "                            out = out.decode(\"utf-8\").split()\n",
    "                        except:\n",
    "                            pass                        \n",
    "                        solution = {}\n",
    "                        if out != []: #### out is [] if the minimization did not converge\n",
    "                            results['noise'].append(noise)\n",
    "                            for i in range(0, nb_parameters): ### first \n",
    "                                lst_name = \"ini_\"+str(param_names[i])\n",
    "                                results[lst_name].append(((float(out[i])-reference_value[i]))/reference_value[i]*100)\n",
    "                            for k in range (nb_parameters, 2*nb_parameters):\n",
    "                                i = k - nb_parameters\n",
    "                                results[param_names[i]].append((float(out[k]) - reference_value[i])/reference_value[i]*100)\n",
    "                                storing_values_for_convergence_check[str(noise)][i].append(float(out[k]))\n",
    "                    if len(storing_values_for_convergence_check[str(noise)][0]) > min_iterations+1:\n",
    "                        converged, crit = helpers.checking_if_converged(storing_values_for_convergence_check[str(noise)], len(storing_processes[str(noise)]), tol=1e-2)\n",
    "                    if converged:\n",
    "                        distribution_converged[noise_lst.index(noise)] = 'converged'\n",
    "                    else:\n",
    "                        distribution_converged[noise_lst.index(noise)] = 'no'\n",
    "    results_all_positions[position] = results\n",
    "    df = pd.DataFrame(results)\n",
    "    df_sorted = df.sort_values(by=\"noise\")\n",
    "    myfile= open(\"./results_estimation-position=\"+str(position), 'w')\n",
    "    myfile.write(df_sorted.to_string(index=False))\n",
    "    myfile.close()\n",
    "plotting_and_writing(positions = positions, parameters_to_identify = parameters_to_identify, results = results_all_positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('MEC581-2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7270dbcea11da5cec531e1718dcee1b0bd6d50ade99199989795797a9208c905"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
